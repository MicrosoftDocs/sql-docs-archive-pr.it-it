---
title: Riferimento tecnico per l'algoritmo Microsoft Decision Trees | Microsoft Docs
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- MAXIMUM_INPUT_ATTRIBUTES parameter
- SPLIT_METHOD parameter
- MINIMUM_SUPPORT parameter
- MAXIMUM_OUTPUT_ATTRIBUTES parameter
- FORCED_REGRESSOR parameter
- decision tree algorithms [Analysis Services]
- decision trees [Analysis Services]
- COMPLEXITY_PENALTY parameter
- SCORE_METHOD parameter
ms.assetid: 1e9f7969-0aa6-465a-b3ea-57b8d1c7a1fd
author: minewiskan
ms.author: owend
ms.openlocfilehash: 0cd0cd3100d0ed1213183815ae41f17cee3baa68
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 08/04/2020
ms.locfileid: "87630149"
---
# <a name="microsoft-decision-trees-algorithm-technical-reference"></a><span data-ttu-id="7ec9c-102">Guida di riferimento tecnico per l'algoritmo Microsoft Decision Trees</span><span class="sxs-lookup"><span data-stu-id="7ec9c-102">Microsoft Decision Trees Algorithm Technical Reference</span></span>
  <span data-ttu-id="7ec9c-103">L'algoritmo [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees è un algoritmo ibrido che incorpora diversi metodi per la creazione di un albero e supporta più attività analitiche, tra le quali sono incluse la regressione, la classificazione e l'associazione.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-103">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm is a hybrid algorithm that incorporates different methods for creating a tree, and supports multiple analytic tasks, including regression, classification, and association.</span></span> <span data-ttu-id="7ec9c-104">Tale algoritmo supporta la modellazione di attributi discreti e continui.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-104">The Microsoft Decision Trees algorithm supports modeling of both discrete and continuous attributes.</span></span>  
  
 <span data-ttu-id="7ec9c-105">In questo argomento viene illustrata l'implementazione dell'algoritmo, viene mostrato come personalizzarne il comportamento in base alle diverse attività e vengono forniti collegamenti a ulteriori informazioni sull'esecuzione di query sui modelli di albero delle decisioni.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-105">This topic explains the implementation of the algorithm, describes how to customize the behavior of the algorithm for different tasks, and provides links to additional information about querying decision tree models.</span></span>  
  
## <a name="implementation-of-the-decision-trees-algorithm"></a><span data-ttu-id="7ec9c-106">Implementazione dell'algoritmo Decision Trees</span><span class="sxs-lookup"><span data-stu-id="7ec9c-106">Implementation of the Decision Trees Algorithm</span></span>  
 <span data-ttu-id="7ec9c-107">L'algoritmo Microsoft Decision Trees applica l'approccio Bayes ai modelli di interazione causale apprendimento ottenendo le distribuzioni posteriori approssimative per i modelli.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-107">The Microsoft Decision Trees algorithm applies the Bayesian approach to learning causal interaction models by obtaining approximate posterior distributions for the models.</span></span> <span data-ttu-id="7ec9c-108">Per una spiegazione dettagliata di questo approccio, vedere il white paper nel sito Microsoft Research relativo alle [informazioni su struttura e parametri](https://go.microsoft.com/fwlink/?LinkId=237640&clcid=0x409).</span><span class="sxs-lookup"><span data-stu-id="7ec9c-108">For a detailed explanation of this approach, see the paper on the Microsoft Research site, by [Structure and Parameter Learning](https://go.microsoft.com/fwlink/?LinkId=237640&clcid=0x409).</span></span>  
  
 <span data-ttu-id="7ec9c-109">La metodologia di valutazione del valore informativo delle *conoscenze precedenti* necessarie per l'apprendimento si basa sul presupposto dell' *equivalenza di probabilità*.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-109">The methodology for assessing the information value of the *priors* needed for learning is based on the assumption of *likelihood equivalence*.</span></span> <span data-ttu-id="7ec9c-110">Questo presupposto indica che i dati non devono permettere la discriminazione delle strutture di rete che altrimenti rappresenterebbero le stesse asserzioni dell'indipendenza condizionale.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-110">This assumption says that data should not help to discriminate network structures that otherwise represent the same assertions of conditional independence.</span></span> <span data-ttu-id="7ec9c-111">Si presuppone che per ogni case sia presente una singola rete Bayes con probabilità a priori, cui è associata una sola misura di confidenza.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-111">Each case is assumed to have a single Bayesian prior network and a single measure of confidence for that network.</span></span>  
  
 <span data-ttu-id="7ec9c-112">Utilizzando queste reti con probabilità a priori, l'algoritmo calcola quindi le *probabilità a posteriori* relative delle strutture di rete a partire dai dati di training correnti e identifica le strutture di rete con le probabilità a posteriori più elevate.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-112">Using these prior networks, the algorithm then computes the relative *posterior probabilities* of network structures given the current training data, and identifies the network structures that have the highest posterior probabilities.</span></span>  
  
 <span data-ttu-id="7ec9c-113">L'algoritmo Microsoft Decision Trees utilizza diversi metodi per calcolare l'albero ideale.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-113">The Microsoft Decision Trees algorithm uses different methods to compute the best tree.</span></span> <span data-ttu-id="7ec9c-114">Il metodo utilizzato dipende dal tipo di attività, ovvero regressione lineare, classificazione o analisi di associazione.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-114">The method used depends on the task, which can be linear regression, classification, or association analysis.</span></span> <span data-ttu-id="7ec9c-115">Un solo modello può contenere più alberi per i diversi attributi stimabili.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-115">A single model can contain multiple trees for different predictable attributes.</span></span> <span data-ttu-id="7ec9c-116">Ogni albero può inoltre contenere più rami, a seconda del numero di attributi e valori presenti nei dati.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-116">Moreover, each tree can contain multiple branches, depending on how many attributes and values there are in the data.</span></span> <span data-ttu-id="7ec9c-117">La forma e la profondità dell'albero incorporato in un determinato modello dipendono dal metodo di valutazione e dagli altri parametri utilizzati.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-117">The shape and depth of the tree built in a particular model depends on the scoring method and other parameters that were used.</span></span> <span data-ttu-id="7ec9c-118">Le modifiche apportate ai parametri possono influire anche sul punto in cui i nodi si dividono.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-118">Changes in the parameters can also affect where the nodes split.</span></span>  
  
### <a name="building-the-tree"></a><span data-ttu-id="7ec9c-119">Compilazione dell'albero</span><span class="sxs-lookup"><span data-stu-id="7ec9c-119">Building the Tree</span></span>  
 <span data-ttu-id="7ec9c-120">Quando l'algoritmo Microsoft Decision Trees crea il set dei possibili valori di input, esegue la *feature selection* per identificare gli attributi e i valori che forniscono il maggior numero di informazioni ignorando i valori che sono molto rari.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-120">When the Microsoft Decision Trees algorithm creates the set of possible input values, it performs *feature selection* to identify the attributes and values that provide the most information, and removes from consideration the values that are very rare.</span></span> <span data-ttu-id="7ec9c-121">L'algoritmo inoltre inserisce i valori in *contenitori*per crearne raggruppamenti che possano essere elaborati come singole unità al fine di ottimizzare le prestazioni.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-121">The algorithm also groups values into *bins*, to create groupings of values that can be processed as a unit to optimize performance.</span></span>  
  
 <span data-ttu-id="7ec9c-122">La compilazione di un albero avviene mediante la definizione delle correlazioni tra un input e il risultato di destinazione.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-122">A tree is built by determining the correlations between an input and the targeted outcome.</span></span> <span data-ttu-id="7ec9c-123">Dopo aver correlato tutti gli attributi, l'algoritmo identifica l'attributo specifico che separa i risultati in modo più netto.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-123">After all the attributes have been correlated, the algorithm identifies the single attribute that most cleanly separates the outcomes.</span></span> <span data-ttu-id="7ec9c-124">Il punto di separazione ideale viene misurato mediante un'equazione che calcola l'Information Gain.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-124">This point of the best separation is measured by using an equation that calculates information gain.</span></span> <span data-ttu-id="7ec9c-125">L'attributo che presenta il miglior punteggio in termini di Information Gain viene utilizzato per dividere i case in subset che vengono quindi analizzati in modo ricorsivo dallo stesso processo fino a quando non sia possibile suddividere ulteriormente l'albero.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-125">The attribute that has the best score for information gain is used to divide the cases into subsets, which are then recursively analyzed by the same process, until the tree cannot be split any more.</span></span>  
  
 <span data-ttu-id="7ec9c-126">L'equazione esatta utilizzata per valutare l'Information Gain dipende dai parametri impostati quando è stato creato l'algoritmo, dal tipo di dati della colonna stimabile e dal tipo di dati dell'input.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-126">The exact equation used to evaluate information gain depends on the parameters set when you created the algorithm, the data type of the predictable column, and the data type of the input.</span></span>  
  
### <a name="discrete-and-continuous-inputs"></a><span data-ttu-id="7ec9c-127">Input discreti e continui</span><span class="sxs-lookup"><span data-stu-id="7ec9c-127">Discrete and Continuous Inputs</span></span>  
 <span data-ttu-id="7ec9c-128">Quando sia l'attributo stimabile sia gli input sono discreti, il conteggio dei risultati per input implica la creazione di una matrice e la generazione di punteggi per ogni cella della matrice.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-128">When the predictable attribute is discrete and the inputs are discrete, counting the outcomes per input is a matter of creating a matrix and generating scores for each cell in the matrix.</span></span>  
  
 <span data-ttu-id="7ec9c-129">Quando invece l'attributo stimabile è discreto e gli input sono continui, l'input delle colonne continue viene discretizzato automaticamente.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-129">However, when the predictable attribute is discrete and the inputs are continuous, the input of the continuous columns are automatically discretized.</span></span> <span data-ttu-id="7ec9c-130">È possibile accettare l'impostazione predefinita e impostare [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] sulla ricerca automatica del numero ottimale di contenitori o controllare il modo in cui gli input continui vengono discretizzati impostando le proprietà <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> e <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> .</span><span class="sxs-lookup"><span data-stu-id="7ec9c-130">You can accept the default and have [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] find the optimum number of bins, or you can control the manner in which continuous inputs are discretized by setting the <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> and <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> properties.</span></span> <span data-ttu-id="7ec9c-131">Per altre informazioni, vedere [Modificare la discretizzazione di una colonna in un modello di data mining](change-the-discretization-of-a-column-in-a-mining-model.md).</span><span class="sxs-lookup"><span data-stu-id="7ec9c-131">For more information, see [Change the Discretization of a Column in a Mining Model](change-the-discretization-of-a-column-in-a-mining-model.md).</span></span>  
  
 <span data-ttu-id="7ec9c-132">Per gli attributi continui, l'algoritmo utilizza una regressione lineare per determinare le divisioni dell'albero delle decisioni.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-132">For continuous attributes, the algorithm uses linear regression to determine where a decision tree splits.</span></span>  
  
 <span data-ttu-id="7ec9c-133">Quando l'attributo stimabile è un tipo di dati numerico continuo, la funzionalità di selezione degli attributi viene applicata anche agli output in modo da ridurre il numero possibile di risultati e da velocizzare la compilazione del modello.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-133">When the predictable attribute is a continuous numeric data type, feature selection is applied to the outputs as well, to reduce the possible number of outcomes and build the model faster.</span></span> <span data-ttu-id="7ec9c-134">È possibile modificare la soglia per la funzionalità di selezione degli attributi e di conseguenza aumentare o ridurre il numero di valori possibili impostando il parametro MAXIMUM_OUTPUT_ATTRIBUTES.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-134">You can change the threshold for feature selection and thereby increase or decrease the number of possible values by setting the MAXIMUM_OUTPUT_ATTRIBUTES parameter.</span></span>  
  
 <span data-ttu-id="7ec9c-135">Per una spiegazione più dettagliata del funzionamento dell'algoritmo [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees nel caso di colonne stimabili discrete, vedere l'articolo relativo alle [informazioni sulle reti Bayesiane riguardanti la combinazione di conoscenza e dati statistici](https://go.microsoft.com/fwlink/?LinkId=45963).</span><span class="sxs-lookup"><span data-stu-id="7ec9c-135">For a more detained explanation about how the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm works with discrete predictable columns, see [Learning Bayesian Networks: The Combination of Knowledge and Statistical Data](https://go.microsoft.com/fwlink/?LinkId=45963).</span></span> <span data-ttu-id="7ec9c-136">Per altre informazioni sul funzionamento dell'algoritmo [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees nel caso di colonne stimabili continue, vedere l'appendice dell'articolo [Autoregressive Tree Models for Time-Series Analysis](https://go.microsoft.com/fwlink/?LinkId=45966)(Modelli di albero autoregressivi per l'analisi delle serie temporali).</span><span class="sxs-lookup"><span data-stu-id="7ec9c-136">For more information about how the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm works with a continuous predictable column, see the appendix of [Autoregressive Tree Models for Time-Series Analysis](https://go.microsoft.com/fwlink/?LinkId=45966).</span></span>  
  
### <a name="scoring-methods-and-feature-selection"></a><span data-ttu-id="7ec9c-137">Metodi di valutazione e caratteristica di selezione degli attributi</span><span class="sxs-lookup"><span data-stu-id="7ec9c-137">Scoring Methods and Feature Selection</span></span>  
 <span data-ttu-id="7ec9c-138">L'algoritmo Microsoft Decision Trees offre tre formule per valutare l'Information Gain, ovvero l'entropia di Shannon, la rete Bayes con probabilità a priori K2 e la rete Bayes Dirichlet con probabilità a priori a distribuzione uniforme.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-138">The Microsoft Decision Trees algorithm offers three formulas for scoring information gain: Shannon's entropy, Bayesian network with K2 prior, and Bayesian network with a uniform Dirichlet distribution of priors.</span></span> <span data-ttu-id="7ec9c-139">Tutti e tre i metodi sono consolidati nel campo del data mining.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-139">All three methods are well established in the data mining field.</span></span> <span data-ttu-id="7ec9c-140">È consigliabile provare a utilizzare diversi parametri e metodi di valutazione in modo da individuare quelli che forniscono i migliori risultati.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-140">We recommend that you experiment with different parameters and scoring methods to determine which provides the best results.</span></span> <span data-ttu-id="7ec9c-141">Per ulteriori informazioni sui metodi di valutazione, vedere [Feature Selection](../../sql-server/install/feature-selection.md).</span><span class="sxs-lookup"><span data-stu-id="7ec9c-141">For more information about these scoring methods, see [Feature Selection](../../sql-server/install/feature-selection.md).</span></span>  
  
 <span data-ttu-id="7ec9c-142">Tutti gli algoritmi di data mining di [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] usano automaticamente la selezione di funzionalità per migliorare l'analisi e ridurre il carico di elaborazione.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-142">All [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] data mining algorithms automatically use feature selection to improve analysis and reduce processing load.</span></span> <span data-ttu-id="7ec9c-143">Il metodo utilizzato per la funzionalità di selezione degli attributi dipende dall'algoritmo impiegato per la compilazione del modello.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-143">The method used for feature selection depends on the algorithm that is used to build the model.</span></span> <span data-ttu-id="7ec9c-144">I parametri dell'algoritmo che controllano la caratteristica di selezione degli attributi per un modello di albero delle decisioni sono MAXIMUM_INPUT_ATTRIBUTES e MAXIMUM_OUTPUT.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-144">The algorithm parameters that control feature selection for a decision trees model are MAXIMUM_INPUT_ATTRIBUTES and MAXIMUM_OUTPUT.</span></span>  
  
|<span data-ttu-id="7ec9c-145">Algoritmo</span><span class="sxs-lookup"><span data-stu-id="7ec9c-145">Algorithm</span></span>|<span data-ttu-id="7ec9c-146">Metodo di analisi</span><span class="sxs-lookup"><span data-stu-id="7ec9c-146">Method of analysis</span></span>|<span data-ttu-id="7ec9c-147">Commenti</span><span class="sxs-lookup"><span data-stu-id="7ec9c-147">Comments</span></span>|  
|---------------|------------------------|--------------|  
|<span data-ttu-id="7ec9c-148">Decision Trees</span><span class="sxs-lookup"><span data-stu-id="7ec9c-148">Decision Trees</span></span>|<span data-ttu-id="7ec9c-149">Punteggio di interesse</span><span class="sxs-lookup"><span data-stu-id="7ec9c-149">Interestingness score</span></span><br /><br /> <span data-ttu-id="7ec9c-150">Entropia di Shannon</span><span class="sxs-lookup"><span data-stu-id="7ec9c-150">Shannon's Entropy</span></span><br /><br /> <span data-ttu-id="7ec9c-151">Bayes con probabilità a priori K2</span><span class="sxs-lookup"><span data-stu-id="7ec9c-151">Bayesian with K2 Prior</span></span><br /><br /> <span data-ttu-id="7ec9c-152">Equivalente Bayes Dirichlet con probabilità a priori a distribuzione uniforme (impostazione predefinita)</span><span class="sxs-lookup"><span data-stu-id="7ec9c-152">Bayesian Dirichlet with uniform prior (default)</span></span>|<span data-ttu-id="7ec9c-153">Se esistono colonne contenenti valori continui non binari, viene utilizzato il punteggio di interesse per tutte le colonne, per assicurare coerenza.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-153">If any columns contain non-binary continuous values, the interestingness score is used for all columns, to ensure consistency.</span></span> <span data-ttu-id="7ec9c-154">In caso contrario, viene utilizzato il metodo predefinito o specificato.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-154">Otherwise, the default or specified method is used.</span></span>|  
|<span data-ttu-id="7ec9c-155">Linear Regression</span><span class="sxs-lookup"><span data-stu-id="7ec9c-155">Linear Regression</span></span>|<span data-ttu-id="7ec9c-156">Punteggio di interesse</span><span class="sxs-lookup"><span data-stu-id="7ec9c-156">Interestingness score</span></span>|<span data-ttu-id="7ec9c-157">L'algoritmo Linear Regression può utilizzare solo il punteggio di interesse, perché supporta solo colonne continue.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-157">Linear Regression only uses interestingness, because it only supports continuous columns.</span></span>|  
  
### <a name="scalability-and-performance"></a><span data-ttu-id="7ec9c-158">Scalabilità e prestazioni</span><span class="sxs-lookup"><span data-stu-id="7ec9c-158">Scalability and Performance</span></span>  
 <span data-ttu-id="7ec9c-159">La classificazione è un'importante strategia di data mining.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-159">Classification is an important data mining strategy.</span></span> <span data-ttu-id="7ec9c-160">In genere, la quantità di informazioni necessaria a classificare i case cresce in modo direttamente proporzionale al numero di record di input.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-160">Generally, the amount of information that is needed to classify the cases grows in direct proportion to the number of input records.</span></span> <span data-ttu-id="7ec9c-161">Ciò limita le dimensioni dei dati classificabili.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-161">This limits the size of the data that can be classified.</span></span> <span data-ttu-id="7ec9c-162">L'algoritmo Microsoft Decision Trees utilizza i metodi seguenti per risolvere questi problemi, migliorare le prestazioni ed eliminare le restrizioni relative alla memoria:</span><span class="sxs-lookup"><span data-stu-id="7ec9c-162">The Microsoft Decision Trees algorithm using uses the following methods to resolve these problems, improve performance, and eliminate memory restrictions:</span></span>  
  
-   <span data-ttu-id="7ec9c-163">Funzionalità di selezione degli attributi per ottimizzare la scelta degli attributi.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-163">Feature selection to optimize the selection of attributes.</span></span>  
  
-   <span data-ttu-id="7ec9c-164">Valutazione con il metodo Bayes per controllare l'aumento delle dimensioni dell'albero.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-164">Bayesian scoring to control tree growth.</span></span>  
  
-   <span data-ttu-id="7ec9c-165">Ottimizzazione della creazione di contenitori per gli attributi continui.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-165">Optimization of binning for continuous attributes.</span></span>  
  
-   <span data-ttu-id="7ec9c-166">Raggruppamento dinamico dei valori di input per individuare i valori più importanti.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-166">Dynamic grouping of input values to determine the most important values.</span></span>  
  
 <span data-ttu-id="7ec9c-167">L'algoritmo Microsoft Decision Trees è veloce e scalabile ed è stato progettato per essere facilmente eseguito in parallelo, ovvero per fare in modo che tutti i processori interagiscano per compilare un singolo modello coerente.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-167">The Microsoft Decision Trees algorithm is fast and scalable, and has been designed to be easily parallelized, meaning that all processors work together to build a single, consistent model.</span></span> <span data-ttu-id="7ec9c-168">La combinazione di queste caratteristiche rende il classificatore dell'albero delle decisioni uno strumento ideale per il data mining.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-168">The combination of these characteristics makes the decision-tree classifier an ideal tool for data mining.</span></span>  
  
 <span data-ttu-id="7ec9c-169">Se i vincoli relativi alle prestazioni sono rigidi, è possibile migliorare il tempo di elaborazione durante il training di un modello di albero delle decisioni tramite i metodi seguenti.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-169">If performance constraints are severe, you might be able to improve processing time during the training of a decision tree model by using the following methods.</span></span> <span data-ttu-id="7ec9c-170">In tal caso, è tuttavia necessario essere consapevoli del fatto che l'eliminazione degli attributi finalizzata al miglioramento delle prestazioni determinerà la modifica dei risultati del modello rendendoli meno rappresentativi della popolazione totale.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-170">However, if you do so, be aware that eliminating attributes to improve processing performance will change the results of the model, and possibly make it less representative of the total population.</span></span>  
  
-   <span data-ttu-id="7ec9c-171">Aumentare il valore del parametro COMPLEXITY_PENALTY per limitare l'aumento delle dimensioni dell'albero.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-171">Increase the value of the COMPLEXITY_PENALTY parameter to limit tree growth.</span></span>  
  
-   <span data-ttu-id="7ec9c-172">Limitare il numero di elementi nei modelli di associazione per compilare un numero limitato di alberi.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-172">Limit the number of items in association models to limit the number of trees that are built.</span></span>  
  
-   <span data-ttu-id="7ec9c-173">Aumentare il valore del parametro MINIMUM_SUPPORT per evitare l'overfitting.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-173">Increase the value of the MINIMUM_SUPPORT parameter to avoid overfitting.</span></span>  
  
-   <span data-ttu-id="7ec9c-174">Limitare il numero di valori discreti di qualsiasi attributo a 10 o un numero inferiore.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-174">Restrict the number of discrete values for any attribute to 10 or less.</span></span> <span data-ttu-id="7ec9c-175">È possibile provare a raggruppare i valori in modi e modelli diversi.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-175">You might try grouping values in different ways in different models.</span></span>  
  
    > [!NOTE]  
    >  <span data-ttu-id="7ec9c-176">È possibile utilizzare gli strumenti di esplorazione dei dati disponibili in  [!INCLUDE[ssISCurrent](../../includes/ssiscurrent-md.md)] per visualizzare la distribuzione di valori nei dati e raggruppare i valori in modo appropriato prima di dare inizio al data mining.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-176">You can use the data exploration tools available in  [!INCLUDE[ssISCurrent](../../includes/ssiscurrent-md.md)] to visualize the distribution of values in your data and group your values appropriately before beginning data mining.</span></span> <span data-ttu-id="7ec9c-177">Per altre informazioni, vedere [Attività Profiling dati e visualizzatore](../../integration-services/control-flow/data-profiling-task-and-viewer.md).</span><span class="sxs-lookup"><span data-stu-id="7ec9c-177">For more information, see [Data Profiling Task and Viewer](../../integration-services/control-flow/data-profiling-task-and-viewer.md).</span></span> <span data-ttu-id="7ec9c-178">È inoltre possibile usare i [componenti aggiuntivi Data Mining per Excel 2007](https://www.microsoft.com/download/details.aspx?id=8569)per esplorare, raggruppare e rietichettare i dati in Microsoft Excel.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-178">You can also use the [Data Mining Add-ins for Excel 2007](https://www.microsoft.com/download/details.aspx?id=8569), to explore, group and relabel data in Microsoft Excel.</span></span>  
  
## <a name="customizing-the-decision-trees-algorithm"></a><span data-ttu-id="7ec9c-179">Personalizzazione dell'algoritmo Decision Trees</span><span class="sxs-lookup"><span data-stu-id="7ec9c-179">Customizing the Decision Trees Algorithm</span></span>  
 <span data-ttu-id="7ec9c-180">L'algoritmo [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees supporta parametri che influiscono sulle prestazioni e sull'accuratezza del modello di data mining risultante.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-180">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports parameters that affect the performance and accuracy of the resulting mining model.</span></span> <span data-ttu-id="7ec9c-181">È anche possibile impostare flag di modellazione nelle colonne del modello o della struttura di data mining per controllare la modalità di elaborazione dei dati.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-181">You can also set modeling flags on the mining model columns or mining structure columns to control the way that data is processed.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="7ec9c-182">L'algoritmo Microsoft Decision Trees è disponibile in tutte le versioni di [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)], tuttavia alcuni parametri avanzati per la personalizzazione del comportamento dell'algoritmo Microsoft Decision Trees sono disponibili per l'uso solo in versioni specifiche di [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)].</span><span class="sxs-lookup"><span data-stu-id="7ec9c-182">The Microsoft Decision Trees algorithm is available in all editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]; however, some advanced parameters for customizing the behavior of the Microsoft Decision Trees algorithm are available for use only in specific editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)].</span></span> <span data-ttu-id="7ec9c-183">Per un elenco delle funzionalità supportate dalle edizioni di [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] , vedere [funzionalità supportate dalle edizioni di SQL Server 2012](https://go.microsoft.com/fwlink/?linkid=232473) ( https://go.microsoft.com/fwlink/?linkid=232473) .</span><span class="sxs-lookup"><span data-stu-id="7ec9c-183">For a list of features that are supported by the editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)], see [Features Supported by the Editions of SQL Server 2012](https://go.microsoft.com/fwlink/?linkid=232473) (https://go.microsoft.com/fwlink/?linkid=232473).</span></span>  
  
### <a name="setting-algorithm-parameters"></a><span data-ttu-id="7ec9c-184">Impostazione dei parametri dell'algoritmo</span><span class="sxs-lookup"><span data-stu-id="7ec9c-184">Setting Algorithm Parameters</span></span>  
 <span data-ttu-id="7ec9c-185">Nella tabella seguente vengono descritti i parametri che è possibile utilizzare con l'algoritmo [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-185">The following table describes the parameters that you can use with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm.</span></span>  
  
 <span data-ttu-id="7ec9c-186">*COMPLEXITY_PENALTY*</span><span class="sxs-lookup"><span data-stu-id="7ec9c-186">*COMPLEXITY_PENALTY*</span></span>  
 <span data-ttu-id="7ec9c-187">Controlla la crescita dell'albero delle decisioni.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-187">Controls the growth of the decision tree.</span></span> <span data-ttu-id="7ec9c-188">Un valore basso comporta l'aumento del numero di divisioni, mentre un valore alto comporta la diminuzione del numero di divisioni.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-188">A low value increases the number of splits, and a high value decreases the number of splits.</span></span> <span data-ttu-id="7ec9c-189">Il valore predefinito è basato sul numero di attributi per un modello specifico, come descritto nell'elenco seguente:</span><span class="sxs-lookup"><span data-stu-id="7ec9c-189">The default value is based on the number of attributes for a particular model, as described in the following list:</span></span>  
  
-   <span data-ttu-id="7ec9c-190">Per un numero di attributi compreso tra 1 e 9, il valore predefinito è 0,5.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-190">For 1 through 9 attributes, the default is 0.5.</span></span>  
  
-   <span data-ttu-id="7ec9c-191">Per un numero di attributi compreso tra 10 e 99, il valore predefinito è 0,9.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-191">For 10 through 99 attributes, the default is 0.9.</span></span>  
  
-   <span data-ttu-id="7ec9c-192">Per un numero di attributi maggiore o uguale a 100, il valore predefinito è 0,99.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-192">For 100 or more attributes, the default is 0.99.</span></span>  
  
 <span data-ttu-id="7ec9c-193">*FORCE_REGRESSOR*</span><span class="sxs-lookup"><span data-stu-id="7ec9c-193">*FORCE_REGRESSOR*</span></span>  
 <span data-ttu-id="7ec9c-194">Forza l'algoritmo a utilizzare le colonne specificate come regressori, indipendentemente dall'importanza delle colonne calcolate dall'algoritmo.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-194">Forces the algorithm to use the specified columns as regressors, regardless of the importance of the columns as calculated by the algorithm.</span></span> <span data-ttu-id="7ec9c-195">Questo parametro viene utilizzato solo per gli alberi delle decisioni che stimano un attributo continuo.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-195">This parameter is only used for decision trees that are predicting a continuous attribute.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="7ec9c-196">Impostando questo parametro, l'algoritmo viene forzato a tentare di utilizzare l'attributo come regressore.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-196">By setting this parameter, you force the algorithm to try to use the attribute as a regressor.</span></span> <span data-ttu-id="7ec9c-197">L'eventualità che l'attributo venga realmente utilizzato come regressore nel modello finale dipende invece dai risultati dell'analisi.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-197">However, whether the attribute is actually used as a regressor in the final model depends on the results of analysis.</span></span> <span data-ttu-id="7ec9c-198">Per individuare le colonne utilizzate come regressori, è possibile eseguire query sul contenuto del modello.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-198">You can find out which columns were used as regressors by querying the model content.</span></span>  
  
 <span data-ttu-id="7ec9c-199">[Disponibile solo in alcune edizioni di [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] ]</span><span class="sxs-lookup"><span data-stu-id="7ec9c-199">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] ]</span></span>  
  
 <span data-ttu-id="7ec9c-200">*MAXIMUM_INPUT_ATTRIBUTES*</span><span class="sxs-lookup"><span data-stu-id="7ec9c-200">*MAXIMUM_INPUT_ATTRIBUTES*</span></span>  
 <span data-ttu-id="7ec9c-201">Definisce il numero di attributi di input che l'algoritmo è in grado di gestire prima di richiamare la funzionalità di selezione degli attributi.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-201">Defines the number of input attributes that the algorithm can handle before it invokes feature selection.</span></span>  
  
 <span data-ttu-id="7ec9c-202">Il valore predefinito è 255.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-202">The default is 255.</span></span>  
  
 <span data-ttu-id="7ec9c-203">Impostare questo valore su 0 per disabilitare la funzionalità di selezione degli attributi.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-203">Set this value to 0 to turn off feature selection.</span></span>  
  
 <span data-ttu-id="7ec9c-204">[Disponibile solo in alcune edizioni di [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span><span class="sxs-lookup"><span data-stu-id="7ec9c-204">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span></span>  
  
 <span data-ttu-id="7ec9c-205">*MAXIMUM_OUTPUT_ATTRIBUTES*</span><span class="sxs-lookup"><span data-stu-id="7ec9c-205">*MAXIMUM_OUTPUT_ATTRIBUTES*</span></span>  
 <span data-ttu-id="7ec9c-206">Definisce il numero di attributi di output che l'algoritmo è in grado di gestire prima di richiamare la funzionalità di selezione degli attributi.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-206">Defines the number of output attributes that the algorithm can handle before it invokes feature selection.</span></span>  
  
 <span data-ttu-id="7ec9c-207">Il valore predefinito è 255.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-207">The default is 255.</span></span>  
  
 <span data-ttu-id="7ec9c-208">Impostare questo valore su 0 per disabilitare la funzionalità di selezione degli attributi.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-208">Set this value to 0 to turn off feature selection.</span></span>  
  
 <span data-ttu-id="7ec9c-209">[Disponibile solo in alcune edizioni di [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span><span class="sxs-lookup"><span data-stu-id="7ec9c-209">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span></span>  
  
 <span data-ttu-id="7ec9c-210">*MINIMUM_SUPPORT*</span><span class="sxs-lookup"><span data-stu-id="7ec9c-210">*MINIMUM_SUPPORT*</span></span>  
 <span data-ttu-id="7ec9c-211">Determina il numero minimo di case foglia necessari per generare una divisione nell'albero delle decisioni.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-211">Determines the minimum number of leaf cases that is required to generate a split in the decision tree.</span></span>  
  
 <span data-ttu-id="7ec9c-212">Il valore predefinito è 10.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-212">The default is 10.</span></span>  
  
 <span data-ttu-id="7ec9c-213">Può essere necessario aumentare il valore se il set di dati è di dimensioni molto elevate per evitare un overtraining.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-213">You may need to increase this value if the dataset is very large, to avoid overtraining.</span></span>  
  
 <span data-ttu-id="7ec9c-214">*SCORE_METHOD*</span><span class="sxs-lookup"><span data-stu-id="7ec9c-214">*SCORE_METHOD*</span></span>  
 <span data-ttu-id="7ec9c-215">Determina il metodo utilizzato per calcolare il punteggio di divisione.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-215">Determines the method that is used to calculate the split score.</span></span> <span data-ttu-id="7ec9c-216">Sono disponibili le opzioni seguenti:</span><span class="sxs-lookup"><span data-stu-id="7ec9c-216">The following options are available:</span></span>  
  
|<span data-ttu-id="7ec9c-217">ID</span><span class="sxs-lookup"><span data-stu-id="7ec9c-217">ID</span></span>|<span data-ttu-id="7ec9c-218">Nome</span><span class="sxs-lookup"><span data-stu-id="7ec9c-218">Name</span></span>|  
|--------|----------|  
|<span data-ttu-id="7ec9c-219">1</span><span class="sxs-lookup"><span data-stu-id="7ec9c-219">1</span></span>|<span data-ttu-id="7ec9c-220">Entropia</span><span class="sxs-lookup"><span data-stu-id="7ec9c-220">Entropy</span></span>|  
|<span data-ttu-id="7ec9c-221">3</span><span class="sxs-lookup"><span data-stu-id="7ec9c-221">3</span></span>|<span data-ttu-id="7ec9c-222">Bayes con probabilità a priori K2</span><span class="sxs-lookup"><span data-stu-id="7ec9c-222">Bayesian with K2 Prior</span></span>|  
|<span data-ttu-id="7ec9c-223">4</span><span class="sxs-lookup"><span data-stu-id="7ec9c-223">4</span></span>|<span data-ttu-id="7ec9c-224">Equivalente Bayes Dirichlet (BDE, Bayesian Dirichlet Equivalent) con probabilità a priori a distribuzione uniforme</span><span class="sxs-lookup"><span data-stu-id="7ec9c-224">Bayesian Dirichlet Equivalent (BDE) with uniform prior</span></span><br /><br /> <span data-ttu-id="7ec9c-225">(predefinito)</span><span class="sxs-lookup"><span data-stu-id="7ec9c-225">(default)</span></span>|  
  
 <span data-ttu-id="7ec9c-226">Il valore predefinito è 4 o BDE.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-226">The default is 4, or BDE.</span></span>  
  
 <span data-ttu-id="7ec9c-227">Per una spiegazione relativa ai metodi di valutazione, vedere [Feature Selection](../../sql-server/install/feature-selection.md).</span><span class="sxs-lookup"><span data-stu-id="7ec9c-227">For an explanation of these scoring methods, see [Feature Selection](../../sql-server/install/feature-selection.md).</span></span>  
  
 <span data-ttu-id="7ec9c-228">*SPLIT_METHOD*</span><span class="sxs-lookup"><span data-stu-id="7ec9c-228">*SPLIT_METHOD*</span></span>  
 <span data-ttu-id="7ec9c-229">Determina il metodo utilizzato per la divisione del nodo.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-229">Determines the method that is used to split the node.</span></span> <span data-ttu-id="7ec9c-230">Sono disponibili le opzioni seguenti:</span><span class="sxs-lookup"><span data-stu-id="7ec9c-230">The following options are available:</span></span>  
  
|<span data-ttu-id="7ec9c-231">ID</span><span class="sxs-lookup"><span data-stu-id="7ec9c-231">ID</span></span>|<span data-ttu-id="7ec9c-232">Nome</span><span class="sxs-lookup"><span data-stu-id="7ec9c-232">Name</span></span>|  
|--------|----------|  
|<span data-ttu-id="7ec9c-233">1</span><span class="sxs-lookup"><span data-stu-id="7ec9c-233">1</span></span>|<span data-ttu-id="7ec9c-234">**Binary:** Indica che l'albero deve essere suddiviso in due rami indipendentemente dal numero effettivo dei valori presenti per l'attributo.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-234">**Binary:** Indicates that regardless of the actual number of values for the attribute, the tree should be split into two branches.</span></span>|  
|<span data-ttu-id="7ec9c-235">2</span><span class="sxs-lookup"><span data-stu-id="7ec9c-235">2</span></span>|<span data-ttu-id="7ec9c-236">**Complete:** Indica che nell'albero possono essere create tante divisioni quanti sono i valori degli attributi.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-236">**Complete:** Indicates that the tree can create as many splits as there are attribute values.</span></span>|  
|<span data-ttu-id="7ec9c-237">3</span><span class="sxs-lookup"><span data-stu-id="7ec9c-237">3</span></span>|<span data-ttu-id="7ec9c-238">**Both:** Specifica che Analysis Services consente di scegliere se utilizzare una divisione binaria o completa per ottenere i risultati migliori.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-238">**Both:** Specifies that Analysis Services can determine whether a binary or complete split should be used to produce the best results.</span></span>|  
  
 <span data-ttu-id="7ec9c-239">Il valore predefinito è 3.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-239">The default is 3.</span></span>  
  
### <a name="modeling-flags"></a><span data-ttu-id="7ec9c-240">Flag di modellazione</span><span class="sxs-lookup"><span data-stu-id="7ec9c-240">Modeling Flags</span></span>  
 <span data-ttu-id="7ec9c-241">L'algoritmo [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees supporta i flag di modellazione seguenti.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-241">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports the following modeling flags.</span></span> <span data-ttu-id="7ec9c-242">Quando si crea la struttura o il modello di data mining, i flag di modellazione vengono definiti per specificare la modalità di gestione dei valori presenti in ogni colonna durante l'analisi.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-242">When you create the mining structure or mining model, you define modeling flags to specify how values in each column are handled during analysis.</span></span> <span data-ttu-id="7ec9c-243">Per altre informazioni, vedere [Flag di modellazione &#40;data mining&#41;](modeling-flags-data-mining.md).</span><span class="sxs-lookup"><span data-stu-id="7ec9c-243">For more information, see [Modeling Flags &#40;Data Mining&#41;](modeling-flags-data-mining.md).</span></span>  
  
|<span data-ttu-id="7ec9c-244">Flag di modellazione</span><span class="sxs-lookup"><span data-stu-id="7ec9c-244">Modeling Flag</span></span>|<span data-ttu-id="7ec9c-245">Descrizione</span><span class="sxs-lookup"><span data-stu-id="7ec9c-245">Description</span></span>|  
|-------------------|-----------------|  
|<span data-ttu-id="7ec9c-246">MODEL_EXISTENCE_ONLY</span><span class="sxs-lookup"><span data-stu-id="7ec9c-246">MODEL_EXISTENCE_ONLY</span></span>|<span data-ttu-id="7ec9c-247">Indica che la colonna verrà considerata come se presentasse due stati possibili: `Missing` e `Existing`.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-247">Means that the column will be treated as having two possible states: `Missing` and `Existing`.</span></span> <span data-ttu-id="7ec9c-248">Un valore Null è un valore mancante.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-248">A null is a missing value.</span></span><br /><br /> <span data-ttu-id="7ec9c-249">Si applica alle colonne del modello di data mining.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-249">Applies to mining model columns.</span></span>|  
|<span data-ttu-id="7ec9c-250">NOT NULL</span><span class="sxs-lookup"><span data-stu-id="7ec9c-250">NOT NULL</span></span>|<span data-ttu-id="7ec9c-251">Indica che la colonna non può contenere un valore Null.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-251">Indicates that the column cannot contain a null.</span></span> <span data-ttu-id="7ec9c-252">Se Analysis Services rileva un valore Null durante il training del modello, viene generato un errore.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-252">An error will result if Analysis Services encounters a null during model training.</span></span><br /><br /> <span data-ttu-id="7ec9c-253">Si applica alle colonne della struttura di data mining.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-253">Applies to mining structure columns.</span></span>|  
  
### <a name="regressors-in-decision-tree-models"></a><span data-ttu-id="7ec9c-254">Regressori nei modelli di albero delle decisioni</span><span class="sxs-lookup"><span data-stu-id="7ec9c-254">Regressors in Decision Tree Models</span></span>  
 <span data-ttu-id="7ec9c-255">Anche se non si utilizza l'algoritmo [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression, qualsiasi modello di albero delle decisioni con input e output numerici continui può contenere nodi che rappresentano una regressione su un attributo continuo.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-255">Even if you do not use the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression algorithm, any decision tree model that has continuous numeric inputs and outputs can potentially include nodes that represent a regression on a continuous attribute.</span></span>  
  
 <span data-ttu-id="7ec9c-256">Non è necessario specificare che una colonna di dati numerici continui rappresenta un regressore.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-256">You do not need to specify that a column of continuous numeric data represents a regressor.</span></span> <span data-ttu-id="7ec9c-257">L'algoritmo [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees consentirà di utilizzare automaticamente la colonna come potenziale regressore e di suddividere il set di dati in aree con modelli significativi anche se non si imposta il flag REGRESSOR nella colonna.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-257">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm will automatically use the column as a potential regressor and partition the dataset into regions with meaningful patterns even if you do not set the REGRESSOR flag on the column.</span></span>  
  
 <span data-ttu-id="7ec9c-258">È invece possibile utilizzare il parametro FORCE_REGRESSOR per assicurarsi che l'algoritmo consenta l'utilizzo di un determinato regressore.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-258">However, you can use the FORCE_REGRESSOR parameter to guarantee that the algorithm will use a particular regressor.</span></span> <span data-ttu-id="7ec9c-259">Questo parametro può essere utilizzato solo con gli algoritmi [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees e [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-259">This parameter can be used only with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees and [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression algorithms.</span></span> <span data-ttu-id="7ec9c-260">Quando si imposta il flag di modellazione, l'algoritmo tenterà di trovare equazioni di regressione nel formato a \* C1 + b \* C2 +... per adattare i modelli nei nodi dell'albero.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-260">When you set the modeling flag, the algorithm will try to find regression equations of the form a\*C1 + b\*C2 + ... to fit the patterns in the nodes of the tree.</span></span> <span data-ttu-id="7ec9c-261">Viene calcolata la somma dei residui e, se la deviazione è eccessiva, nell'albero viene forzata una divisione.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-261">The sum of the residuals is calculated, and if the deviation is too great, a split is forced in the tree.</span></span>  
  
 <span data-ttu-id="7ec9c-262">Se, ad esempio, si stima il comportamento di acquisto dei clienti utilizzando **Income** come attributo ed è stato impostato il flag di modellazione REGRESSOR nella colonna, l'algoritmo tenta innanzitutto di adattare i valori **Income** utilizzando una formula di regressione standard.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-262">For example, if you are predicting customer purchasing behavior using **Income** as an attribute, and set the REGRESSOR modeling flag on the column, the algorithm will first try to fit the **Income** values by using a standard regression formula.</span></span> <span data-ttu-id="7ec9c-263">Se la deviazione è eccessiva, la formula di regressione viene abbandonata e l'albero viene diviso in base a un altro attributo.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-263">If the deviation is too great, the regression formula is abandoned and the tree will be split on another attribute.</span></span> <span data-ttu-id="7ec9c-264">L'algoritmo Decision Trees tenta quindi di adattare un regressore per il reddito in ognuno dei rami dopo la divisione.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-264">The decision tree algorithm will then try to fit a regressor for income in each of the branches after the split.</span></span>  
  
## <a name="requirements"></a><span data-ttu-id="7ec9c-265">Requisiti</span><span class="sxs-lookup"><span data-stu-id="7ec9c-265">Requirements</span></span>  
 <span data-ttu-id="7ec9c-266">Un modello di albero delle decisioni deve contenere una colonna chiave, le colonne di input e almeno una colonna stimabile.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-266">A decision tree model must contain a key column, input columns, and at least one predictable column.</span></span>  
  
### <a name="input-and-predictable-columns"></a><span data-ttu-id="7ec9c-267">Colonne di input e stimabili</span><span class="sxs-lookup"><span data-stu-id="7ec9c-267">Input and Predictable Columns</span></span>  
 <span data-ttu-id="7ec9c-268">L'algoritmo [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees supporta le colonne di input e le colonne stimabili specifiche riportate nella tabella seguente.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-268">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports the specific input columns and predictable columns that are listed in the following table.</span></span> <span data-ttu-id="7ec9c-269">Per altre informazioni sul significato dei tipi di contenuto usati in un modello di data mining, vedere [Tipi di contenuto &#40;Data mining&#41;](content-types-data-mining.md).</span><span class="sxs-lookup"><span data-stu-id="7ec9c-269">For more information about what the content types mean when used in a mining model, see [Content Types &#40;Data Mining&#41;](content-types-data-mining.md).</span></span>  
  
|<span data-ttu-id="7ec9c-270">Colonna</span><span class="sxs-lookup"><span data-stu-id="7ec9c-270">Column</span></span>|<span data-ttu-id="7ec9c-271">Tipi di contenuto</span><span class="sxs-lookup"><span data-stu-id="7ec9c-271">Content types</span></span>|  
|------------|-------------------|  
|<span data-ttu-id="7ec9c-272">Attributo di input</span><span class="sxs-lookup"><span data-stu-id="7ec9c-272">Input attribute</span></span>|<span data-ttu-id="7ec9c-273">Continuous, Cyclical, Discrete, Discretized, Key, Ordered, Table</span><span class="sxs-lookup"><span data-stu-id="7ec9c-273">Continuous, Cyclical, Discrete, Discretized, Key, Ordered, Table</span></span>|  
|<span data-ttu-id="7ec9c-274">Attributo stimabile</span><span class="sxs-lookup"><span data-stu-id="7ec9c-274">Predictable attribute</span></span>|<span data-ttu-id="7ec9c-275">Continuous, Cyclical, Discrete, Discretized, Ordered, Table</span><span class="sxs-lookup"><span data-stu-id="7ec9c-275">Continuous, Cyclical, Discrete, Discretized, Ordered, Table</span></span>|  
  
> [!NOTE]  
>  <span data-ttu-id="7ec9c-276">Sono supportati i tipi di contenuto Cyclical e Ordered ma l'algoritmo li considera come valori discreti e non esegue un'elaborazione speciale.</span><span class="sxs-lookup"><span data-stu-id="7ec9c-276">Cyclical and Ordered content types are supported, but the algorithm treats them as discrete values and does not perform special processing.</span></span>  
  
## <a name="see-also"></a><span data-ttu-id="7ec9c-277">Vedere anche</span><span class="sxs-lookup"><span data-stu-id="7ec9c-277">See Also</span></span>  
 <span data-ttu-id="7ec9c-278">[Algoritmo Microsoft Decision Trees](microsoft-decision-trees-algorithm.md) </span><span class="sxs-lookup"><span data-stu-id="7ec9c-278">[Microsoft Decision Trees Algorithm](microsoft-decision-trees-algorithm.md) </span></span>  
 <span data-ttu-id="7ec9c-279">[Esempi di query sul modello Decision Trees](decision-trees-model-query-examples.md) </span><span class="sxs-lookup"><span data-stu-id="7ec9c-279">[Decision Trees Model Query Examples](decision-trees-model-query-examples.md) </span></span>  
 [<span data-ttu-id="7ec9c-280">Contenuto dei modelli di data mining per i modelli di albero delle decisioni &#40;Analysis Services - Data mining&#41;</span><span class="sxs-lookup"><span data-stu-id="7ec9c-280">Mining Model Content for Decision Tree Models &#40;Analysis Services - Data Mining&#41;</span></span>](mining-model-content-for-decision-tree-models-analysis-services-data-mining.md)  
  
  
